{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79075b98",
   "metadata": {
    "papermill": {
     "duration": 0.008664,
     "end_time": "2022-09-18T11:16:58.820647",
     "exception": false,
     "start_time": "2022-09-18T11:16:58.811983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7045088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:16:58.837836Z",
     "iopub.status.busy": "2022-09-18T11:16:58.837453Z",
     "iopub.status.idle": "2022-09-18T11:17:28.574024Z",
     "shell.execute_reply": "2022-09-18T11:17:28.572860Z"
    },
    "papermill": {
     "duration": 29.747521,
     "end_time": "2022-09-18T11:17:28.576681",
     "exception": false,
     "start_time": "2022-09-18T11:16:58.829160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install tokenizer\n",
    "# !pip install gensim\n",
    "# !pip install tensorflow-gpu==2.6.0\n",
    "# !pip install numpy==1.20.0\n",
    "# !pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc4719e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:17:28.596810Z",
     "iopub.status.busy": "2022-09-18T11:17:28.596409Z",
     "iopub.status.idle": "2022-09-18T11:17:41.964726Z",
     "shell.execute_reply": "2022-09-18T11:17:41.963657Z"
    },
    "papermill": {
     "duration": 13.385095,
     "end_time": "2022-09-18T11:17:41.968262",
     "exception": false,
     "start_time": "2022-09-18T11:17:28.583167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/sufia/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.normalizers import NFD, NFKC,Sequence\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from transformers import GPT2Tokenizer, GPT2Config, TFGPT2LMHeadModel\n",
    "from transformers import WEIGHTS_NAME, CONFIG_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f6e8d",
   "metadata": {},
   "source": [
    "# Dataset path\n",
    "This dataset is prothom alo new data. it containt's 8168 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f050b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ja/opnion_text_512.txt\"\n",
    "tokenizer_save_path = \"tokenizer_voc\"\n",
    "save_model = \"bangla_gpt2\"\n",
    "os.makedirs(tokenizer_save_path, exist_ok= True)\n",
    "os.makedirs(save_model, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66819e",
   "metadata": {
    "papermill": {
     "duration": 0.006308,
     "end_time": "2022-09-18T11:17:41.981605",
     "exception": false,
     "start_time": "2022-09-18T11:17:41.975297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37852fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:17:42.017141Z",
     "iopub.status.busy": "2022-09-18T11:17:42.016865Z",
     "iopub.status.idle": "2022-09-18T11:17:42.021619Z",
     "shell.execute_reply": "2022-09-18T11:17:42.020677Z"
    },
    "papermill": {
     "duration": 0.01366,
     "end_time": "2022-09-18T11:17:42.023559",
     "exception": false,
     "start_time": "2022-09-18T11:17:42.009899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer_func(text: str, token_min_len: int, token_max_len: int, lower: bool) -> list:\n",
    "    return [token for token in text.split() if token_min_len <= len(token) <= token_max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3cadb",
   "metadata": {
    "papermill": {
     "duration": 0.035305,
     "end_time": "2022-09-18T11:29:04.393031",
     "exception": false,
     "start_time": "2022-09-18T11:29:04.357726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689be6c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:29:04.552023Z",
     "iopub.status.busy": "2022-09-18T11:29:04.551736Z",
     "iopub.status.idle": "2022-09-18T11:29:04.557403Z",
     "shell.execute_reply": "2022-09-18T11:29:04.556572Z"
    },
    "papermill": {
     "duration": 0.043441,
     "end_time": "2022-09-18T11:29:04.559458",
     "exception": false,
     "start_time": "2022-09-18T11:29:04.516017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_bpe_tokenizer(data_path:str=\"\", tokenizer_save_path:str=\"\")->None:\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.normalizer = Sequence([NFKC()])\n",
    "    tokenizer.pre_tokenizer = ByteLevel()\n",
    "    tokenizer.decoder = ByteLevelDecoder()\n",
    "\n",
    "    trainer = BpeTrainer(\n",
    "        vocab_size=50000, \n",
    "        show_progress=True,\n",
    "        inital_alphabet=ByteLevel.alphabet(),\n",
    "        special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"]\n",
    "    )\n",
    "    tokenizer.train(files=[data_path], trainer=trainer)\n",
    "    tokenizer.model.save(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce79e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwargs option inital_alphabet\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_bpe_tokenizer(data_path=data_path, tokenizer_save_path=tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d62fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "বহুল আলোচিত দশম জাতীয় সংসদ নির্বাচন অনুষ্ঠিত হতে আর মাত্র কটা দিন বাকি। নির্বাচনের প্রধান ও আলোচিত রাজনৈতিক দল আওয়ামী লীগ নির্বাচনের মাত্র এক সপ্তাহ আগে তাদের নির্বাচনী ইশতেহার ঘোষণা করেছে। ৫০ পৃষ্ঠাসংবলিত এবারের ইশতেহারে ‘সংখ্যালঘু. ক্ষুদ্র জাতিসত্তা. অনুন্নত সম্প্রদায় ও পার্বত্য চট্টগ্রাম’ শিরোনামে (২২.১ ও ২২.২ ধারায়) কিছু গতানুগতিক প্রতিশ্রুতি প্রদান করা হয়েছে। অন্যদিকে. নির্বাচন কমিশনের আরোপিত প্রয়োজনীয় শর্তাবলি পূরণ করতে না পারায় পার্বত্য চট্টগ্রামের আঞ্চলিক দলগুলোকে নির্বাচন কমিশন থেকে নিবন্ধন দেওয়া হ\n"
     ]
    }
   ],
   "source": [
    " with open(data_path, \"r\", encoding='utf-8') as f:\n",
    "    x = f.read().split(\"\\n\")\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1902448d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:31:45.596384Z",
     "iopub.status.busy": "2022-09-18T11:31:45.595655Z",
     "iopub.status.idle": "2022-09-18T11:31:45.673903Z",
     "shell.execute_reply": "2022-09-18T11:31:45.671954Z"
    },
    "papermill": {
     "duration": 0.121342,
     "end_time": "2022-09-18T11:31:45.678367",
     "exception": false,
     "start_time": "2022-09-18T11:31:45.557025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_save_path,  unk_token=\"[UNK]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c7953",
   "metadata": {},
   "source": [
    "# Train Tokenizer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7a510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 23:32:54.200787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.219350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.219661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.221067: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 23:32:54.222046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.222339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.222617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.652017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.652306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.652557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-26 23:32:54.652816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "text = \"গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায় আজ বৃহস্পতিবার রাতের টিফিন খেয়ে একটি পোশাক কারখানার ৫০০ শ্রমিক অসুস্থ হয়ে পড়েছেন।\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2ae3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 94), dtype=int32, numpy=\n",
       "array([[ 208,  172,  211,  197,  200,  186,  174,  173,  174,  185,  172,\n",
       "         183,  176,  178,  225,  180,  275,  174,  750,  173,  183,  172,\n",
       "         174,  207,  173,  183,  176,  434,  172,  183,  172,  475,  172,\n",
       "         180,  172,  178,  181,  517,  188,  247,  698,  175,  344,  176,\n",
       "         182,  172,  174,  228,  172,  179,  173,  174,  290,  176,  272,\n",
       "         176,  177,  262,  173,  178,  210,  286,  176,  190,  191,  198,\n",
       "         172,  180,  185,  172,  790,  172,  177,  172,  174, 1530,  229,\n",
       "         175,  310,  176,  180,  381,  186,  194,  175,  217,  234,  210,\n",
       "         350,  210,  203,  173,  177,  193]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63ad2af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208, 172, 211, 197, 200, 186, 174, 173, 174, 185, 172, 183, 176, 178, 225, 180, 275, 174, 750, 173, 183, 172, 174, 207, 173, 183, 176, 434, 172, 183, 172, 475, 172, 180, 172, 178, 181, 517, 188, 247, 698, 175, 344, 176, 182, 172, 174, 228, 172, 179, 173, 174, 290, 176, 272, 176, 177, 262, 173, 178, 210, 286, 176, 190, 191, 198, 172, 180, 185, 172, 790, 172, 177, 172, 174, 1530, 229, 175, 310, 176, 180, 381, 186, 194, 175, 217, 234, 210, 350, 210, 203, 173, 177, 193]\n"
     ]
    }
   ],
   "source": [
    "string_tokenized = tokenizer.encode(text)\n",
    "print(string_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a1d451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['গ', 'া', 'জ', 'ী', 'প', 'ু', 'র', 'ে', 'র', ' ক', 'া', 'ল', 'ি', 'য', '়া', 'ক', 'ৈ', 'র', ' উপজ', 'ে', 'ল', 'া', 'র', ' ত', 'ে', 'ল', 'ি', 'রচ', 'া', 'ল', 'া', ' এল', 'া', 'ক', 'া', 'য', '়', ' আজ', ' ব', 'ৃ', 'হস', '্', 'পত', 'ি', 'ব', 'া', 'র', ' র', 'া', 'ত', 'ে', 'র', ' ট', 'ি', 'ফ', 'ি', 'ন', ' খ', 'ে', 'য', '়ে', ' একট', 'ি', ' প', 'ো', 'শ', 'া', 'ক', ' ক', 'া', 'রখ', 'া', 'ন', 'া', 'র', ' ৫০০', ' শ', '্', 'রম', 'ি', 'ক', ' অস', 'ু', 'স', '্', 'থ', ' হয', '়ে', ' পড', '়ে', 'ছ', 'ে', 'ন', '।']\n"
     ]
    }
   ],
   "source": [
    "token_list = [tokenizer.decode(i) for i in string_tokenized]\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70554e0",
   "metadata": {
    "papermill": {
     "duration": 0.052334,
     "end_time": "2022-09-18T11:31:45.783744",
     "exception": false,
     "start_time": "2022-09-18T11:31:45.731410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441041d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:31:46.146364Z",
     "iopub.status.busy": "2022-09-18T11:31:46.143490Z",
     "iopub.status.idle": "2022-09-18T11:31:46.157201Z",
     "shell.execute_reply": "2022-09-18T11:31:46.156261Z"
    },
    "papermill": {
     "duration": 0.076976,
     "end_time": "2022-09-18T11:31:46.161903",
     "exception": false,
     "start_time": "2022-09-18T11:31:46.084927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"unk_token\": \"<unk>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"mask_token\": \"<mask>\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1503993c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:31:46.272440Z",
     "iopub.status.busy": "2022-09-18T11:31:46.272094Z",
     "iopub.status.idle": "2022-09-18T11:31:46.276809Z",
     "shell.execute_reply": "2022-09-18T11:31:46.276000Z"
    },
    "papermill": {
     "duration": 0.0635,
     "end_time": "2022-09-18T11:31:46.280537",
     "exception": false,
     "start_time": "2022-09-18T11:31:46.217037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954c4b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:31:46.389980Z",
     "iopub.status.busy": "2022-09-18T11:31:46.389640Z",
     "iopub.status.idle": "2022-09-18T11:31:46.517694Z",
     "shell.execute_reply": "2022-09-18T11:31:46.516876Z"
    },
    "papermill": {
     "duration": 0.185537,
     "end_time": "2022-09-18T11:31:46.520274",
     "exception": false,
     "start_time": "2022-09-18T11:31:46.334737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 23:33:08.306529: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87302496",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:31:46.632035Z",
     "iopub.status.busy": "2022-09-18T11:31:46.631621Z",
     "iopub.status.idle": "2022-09-18T11:33:00.753791Z",
     "shell.execute_reply": "2022-09-18T11:33:00.752733Z"
    },
    "papermill": {
     "duration": 74.216008,
     "end_time": "2022-09-18T11:33:00.791858",
     "exception": false,
     "start_time": "2022-09-18T11:31:46.575850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done tokenizing\n"
     ]
    }
   ],
   "source": [
    "paths = [data_path]\n",
    "single_string = ''\n",
    "for filename in paths:\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        x = f.read()\n",
    "    single_string += x + tokenizer.eos_token\n",
    "\n",
    "string_tokenized = tokenizer.encode(single_string)\n",
    "print(\"Done tokenizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef7fea48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:33:00.864527Z",
     "iopub.status.busy": "2022-09-18T11:33:00.863617Z",
     "iopub.status.idle": "2022-09-18T11:34:21.372525Z",
     "shell.execute_reply": "2022-09-18T11:34:21.371508Z"
    },
    "papermill": {
     "duration": 80.582431,
     "end_time": "2022-09-18T11:34:21.409935",
     "exception": false,
     "start_time": "2022-09-18T11:33:00.827504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating dataset\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "block_size = 200\n",
    "BATCH_SIZE = 12\n",
    "BUFFER_SIZE = 1000\n",
    "for i in range(0, len(string_tokenized) - block_size + 1, block_size):\n",
    "#     print(string_tokenized[i:i + block_size])\n",
    "    examples.append(string_tokenized[i:i + block_size])\n",
    "inputs, labels = [], []\n",
    "\n",
    "for ex in examples:\n",
    "    inputs.append(ex[:-1])\n",
    "    labels.append(ex[1:])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(\"Done creating dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "747acdcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:34:21.482928Z",
     "iopub.status.busy": "2022-09-18T11:34:21.482600Z",
     "iopub.status.idle": "2022-09-18T11:34:21.508117Z",
     "shell.execute_reply": "2022-09-18T11:34:21.507225Z"
    },
    "papermill": {
     "duration": 0.064357,
     "end_time": "2022-09-18T11:34:21.510201",
     "exception": false,
     "start_time": "2022-09-18T11:34:21.445844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=[\n",
    "              loss, *[None] * model.config.n_layer], metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c80074eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T11:34:21.584723Z",
     "iopub.status.busy": "2022-09-18T11:34:21.583785Z",
     "iopub.status.idle": "2022-09-18T21:14:33.448701Z",
     "shell.execute_reply": "2022-09-18T21:14:33.447797Z"
    },
    "papermill": {
     "duration": 34811.905334,
     "end_time": "2022-09-18T21:14:33.450864",
     "exception": false,
     "start_time": "2022-09-18T11:34:21.545530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24345/24345 [==============================] - 3354s 138ms/step - loss: 2.1462 - accuracy: 0.5140\n",
      "Epoch 2/100\n",
      "24345/24345 [==============================] - 3333s 137ms/step - loss: 1.6476 - accuracy: 0.6100\n",
      "Epoch 3/100\n",
      "24345/24345 [==============================] - 3337s 137ms/step - loss: 1.5232 - accuracy: 0.6353\n",
      "Epoch 4/100\n",
      "24345/24345 [==============================] - 3333s 137ms/step - loss: 1.4511 - accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "24345/24345 [==============================] - 3332s 137ms/step - loss: 1.4006 - accuracy: 0.6602\n",
      "Epoch 6/100\n",
      "24345/24345 [==============================] - 3329s 137ms/step - loss: 1.3618 - accuracy: 0.6680\n",
      "Epoch 7/100\n",
      "24345/24345 [==============================] - 3334s 137ms/step - loss: 1.3303 - accuracy: 0.6743\n",
      "Epoch 8/100\n",
      "24345/24345 [==============================] - 3333s 137ms/step - loss: 1.3036 - accuracy: 0.6796\n",
      "Epoch 9/100\n",
      "24345/24345 [==============================] - 3440s 141ms/step - loss: 1.2802 - accuracy: 0.6842\n",
      "Epoch 10/100\n",
      "24345/24345 [==============================] - 3354s 138ms/step - loss: 1.2594 - accuracy: 0.6884\n",
      "Epoch 11/100\n",
      "24345/24345 [==============================] - 3358s 138ms/step - loss: 1.2406 - accuracy: 0.6920\n",
      "Epoch 12/100\n",
      "24345/24345 [==============================] - 3366s 138ms/step - loss: 1.2234 - accuracy: 0.6954\n",
      "Epoch 13/100\n",
      "24345/24345 [==============================] - 3367s 138ms/step - loss: 1.2075 - accuracy: 0.6986\n",
      "Epoch 14/100\n",
      "24345/24345 [==============================] - 3378s 139ms/step - loss: 1.1926 - accuracy: 0.7014\n",
      "Epoch 15/100\n",
      "24345/24345 [==============================] - 3332s 137ms/step - loss: 1.1787 - accuracy: 0.7042\n",
      "Epoch 16/100\n",
      "24345/24345 [==============================] - 3346s 137ms/step - loss: 1.1655 - accuracy: 0.7067\n",
      "Epoch 17/100\n",
      "24345/24345 [==============================] - 3450s 142ms/step - loss: 1.1532 - accuracy: 0.7091\n",
      "Epoch 18/100\n",
      "24345/24345 [==============================] - 3451s 142ms/step - loss: 1.1414 - accuracy: 0.7114\n",
      "Epoch 19/100\n",
      "24345/24345 [==============================] - 3331s 137ms/step - loss: 1.1304 - accuracy: 0.7135\n",
      "Epoch 20/100\n",
      "24345/24345 [==============================] - 3323s 137ms/step - loss: 1.1198 - accuracy: 0.7156\n",
      "Epoch 21/100\n",
      "24345/24345 [==============================] - 3441s 141ms/step - loss: 1.1097 - accuracy: 0.7176\n",
      "Epoch 22/100\n",
      "24345/24345 [==============================] - 3489s 143ms/step - loss: 1.1002 - accuracy: 0.7194\n",
      "Epoch 23/100\n",
      "24345/24345 [==============================] - 3449s 142ms/step - loss: 1.0909 - accuracy: 0.7212\n",
      "Epoch 24/100\n",
      "24345/24345 [==============================] - 3401s 140ms/step - loss: 1.0820 - accuracy: 0.7229\n",
      "Epoch 25/100\n",
      " 5768/24345 [======>.......................] - ETA: 42:31 - loss: 1.0867 - accuracy: 0.7224"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/sufia/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "history = model.fit(dataset, epochs=num_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bca41664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:14:47.667686Z",
     "iopub.status.busy": "2022-09-18T21:14:47.666693Z",
     "iopub.status.idle": "2022-09-18T21:14:48.784785Z",
     "shell.execute_reply": "2022-09-18T21:14:48.783864Z"
    },
    "papermill": {
     "duration": 8.442025,
     "end_time": "2022-09-18T21:14:48.786940",
     "exception": false,
     "start_time": "2022-09-18T21:14:40.344915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2_bangla/tokenizer_config.json',\n",
       " './gpt2_bangla/special_tokens_map.json',\n",
       " './gpt2_bangla/vocab.json',\n",
       " './gpt2_bangla/merges.txt',\n",
       " './gpt2_bangla/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = './gpt2_bangla'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "output_model_file = os.path.join(save_path, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(save_path, CONFIG_NAME)\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "\n",
    "# save tokenizer\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a334ea6",
   "metadata": {
    "papermill": {
     "duration": 7.31327,
     "end_time": "2022-09-18T21:15:03.933208",
     "exception": false,
     "start_time": "2022-09-18T21:14:56.619938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9a4de59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:15:18.372630Z",
     "iopub.status.busy": "2022-09-18T21:15:18.372239Z",
     "iopub.status.idle": "2022-09-18T21:15:19.503599Z",
     "shell.execute_reply": "2022-09-18T21:15:19.502573Z"
    },
    "papermill": {
     "duration": 8.400337,
     "end_time": "2022-09-18T21:15:19.505778",
     "exception": false,
     "start_time": "2022-09-18T21:15:11.105441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./gpt2_bangla.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "output_dir = \"./gpt2_bangla\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)\n",
    "model = TFGPT2LMHeadModel.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "322c7a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:15:34.143142Z",
     "iopub.status.busy": "2022-09-18T21:15:34.142721Z",
     "iopub.status.idle": "2022-09-18T21:15:34.148527Z",
     "shell.execute_reply": "2022-09-18T21:15:34.147881Z"
    },
    "papermill": {
     "duration": 7.217596,
     "end_time": "2022-09-18T21:15:34.150302",
     "exception": false,
     "start_time": "2022-09-18T21:15:26.932706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text =\"বহুল আলোচিত দশম জাতীয় সংসদ নির্বাচন অনুষ্ঠিত হতে আর মাত্র কটা দিন বাকি।\"\n",
    "text = \"বহুল আলোচিত দশম জাতীয় সংসদ\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "706e6386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n",
       "array([[590, 186, 183, 304, 191, 215, 176, 179, 782, 222, 172, 179, 197,\n",
       "        170, 166, 187, 219, 436]], dtype=int32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80a08c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "বহুল আলোচিত দশম জাতীয় সংসদ\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(input_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdf24789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:15:48.620004Z",
     "iopub.status.busy": "2022-09-18T21:15:48.619599Z",
     "iopub.status.idle": "2022-09-18T21:15:54.728800Z",
     "shell.execute_reply": "2022-09-18T21:15:54.727784Z"
    },
    "papermill": {
     "duration": 13.283546,
     "end_time": "2022-09-18T21:15:54.731448",
     "exception": false,
     "start_time": "2022-09-18T21:15:41.447902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to 2 (first `eos_token_id`) to generate sequence\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=175,\n",
    "    num_beams=10,\n",
    "    temperature=0.7,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38017fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6737b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:16:09.552989Z",
     "iopub.status.busy": "2022-09-18T21:16:09.552590Z",
     "iopub.status.idle": "2022-09-18T21:16:09.560895Z",
     "shell.execute_reply": "2022-09-18T21:16:09.559831Z"
    },
    "papermill": {
     "duration": 6.998535,
     "end_time": "2022-09-18T21:16:09.564292",
     "exception": false,
     "start_time": "2022-09-18T21:16:02.565757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "বহুল আলোচিত দশম জাতীয় সংসদ নির্বাচনের তফসিল ঘোষণার পর থেকে এ পর্যন্ত বিভিন্ন স্থানে সহিংসতা ও নাশকতা বেড়ে গেছে। সাম্প্রতিক কালে রাজশাহী. খুলনা. বরিশালসহ অন্য সিটি করপোরেশনে যেসব নেতা-কর্মী গুরুতর অপরাধে মামলা দিচ্ছেন. তাঁরা ক্ষমতাসীন দল ও আইনশৃঙ্খলা রক্ষাকা\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0a689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f212c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35968.71131,
   "end_time": "2022-09-18T21:16:19.767498",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-18T11:16:51.056188",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
